{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42eed5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import accelerate\n",
    "# import flash_attn\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoConfig, # load the configuration of pre-trained model. architecture and hyperparameter of the model\n",
    "    AutoModelForCausalLM, # loads the pretrained causal language model for task like text generation\n",
    "    AutoTokenizer, # load the tokenizer with a pre-trained model. convert the text to tokens\n",
    "    DataCollatorForLanguageModeling, # designed for language modelling task. prepares batches for training by handling padding and masking\n",
    "    EarlyStoppingCallback,  # is used to stop the training, if in the validation performance stops improving to save time and resources\n",
    "    Trainer, # A high level API for training and evaluating the transformers. \n",
    "    TrainingArguments, # define the hyperparameter like learning rate, batch size, epoch, weight decay. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fb38614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from accelerate) (2.5.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from accelerate) (0.7.0)\n",
      "Requirement already satisfied: filelock in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.7.0)\n",
      "Requirement already satisfied: requests in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: networkx in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting sympy==1.13.1 (from torch>=2.0.0->accelerate)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/data/tools/miniconda3/envs/torch_gpu/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.11.12)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Installing collected packages: sympy, accelerate\n",
      "\u001b[2K  Attempting uninstall: sympy\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [accelerate]2\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.12.0 sympy-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate\n",
    "# !pip install flash-attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c50b2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
